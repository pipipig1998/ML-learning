{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "critical-pakistan",
   "metadata": {},
   "source": [
    "# 指南\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-sphere",
   "metadata": {},
   "source": [
    "## Eager Execution\n",
    "Eager Execution 是一种命令式编程环境，可立即评估运算，无需构建计算图：运算会返回具体的值，而非构建供稍后运行的计算图。\n",
    "1. 直观的界面 - 自然地组织代码结构并使用 Python 数据结构。快速迭代小模型和小数据。\n",
    "2. 更方便的调试功能 - 直接调用运算以检查正在运行的模型并测试更改。使用标准 Python 调试工具立即报告错误。\n",
    "3. 自然的控制流 - 使用 Python 而非计算图控制流，简化了动态模型的规范。\n",
    "**Eager Execution 支持大部分 TensorFlow 运算和 GPU 加速。**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "immediate-jackson",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T12:31:48.569960Z",
     "start_time": "2021-04-08T12:31:45.339727Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import cProfile\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "editorial-region",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:30:04.370571Z",
     "start_time": "2021-04-08T08:30:04.361596Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello,Tensorflow,矩阵计算得[[4.]]\n"
     ]
    }
   ],
   "source": [
    "# 在 Tensorflow 2.0 中，默认启用 Eager Execution。\n",
    "tf.executing_eagerly()\n",
    "x=[\n",
    "    [2.0]\n",
    "]\n",
    "m=tf.matmul(x,x)\n",
    "print('Hello,Tensorflow,矩阵计算得{}'.format(m))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "particular-flash",
   "metadata": {},
   "source": [
    "&ensp;&ensp;启用 Eager Execution 会改变 TensorFlow 运算的行为方式,**现在它们会立即评估并将值返回给 Python**。\n",
    "<br>\n",
    "&ensp;&ensp;tf.Tensor 对象会引用**具体值**，而非指向计算图中节点的符号句柄。可以轻松使用 print() 或调试程序检查结果。评估、输出和检查张量值不会中断计算梯度的流程。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cubic-albania",
   "metadata": {},
   "source": [
    "### 配合numpy进行使用\n",
    "NumPy 运算接受 tf.Tensor 参数。<br>\n",
    "tf.math 运算会将 Python 对象和 NumPy 数组转换为 tf.Tensor 对象。<br>\n",
    "tf.Tensor.numpy 方法会以 NumPy ndarray 的形式返回该对象的值。\n",
    "<br>\n",
    "tensor和Numpy数组之间具有很高的相似性，彼此之间的互操作也非常简单高效。需要注意的是，**Numpy和Tensor共享内存**。由于Numpy历史悠久，支持丰富的操作，所以当遇到Tensor不支持的操作时，可先转成Numpy数组，处理后再转回tensor，其**转换开销很小**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "double-athletics",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:37:13.074705Z",
     "start_time": "2021-04-08T08:37:12.627514Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32)\n",
      "[[ 7 10]\n",
      " [15 22]]\n",
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 2  6]\n",
      " [12 20]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 创建tensorflow的常量\n",
    "a=tf.constant([\n",
    "    [1,2],\n",
    "    [3,4]\n",
    "])\n",
    "print(a)\n",
    "\n",
    "\n",
    "# 可以直接用numpy的运算\n",
    "b=np.matmul(a,a)\n",
    "print(b)\n",
    "\n",
    "\n",
    "# 广播机制\n",
    "b=tf.add(a,1)\n",
    "print(b)\n",
    "# [[2 3]\n",
    "#  [4 5]]\n",
    "\n",
    "\n",
    "# 元素乘法，等价于np.multiply(a,b)\n",
    "print(a*b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documentary-extreme",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 动态流控制\n",
    "在执行模型时，主机语言的所有功能均可用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "finite-future",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:55:48.963105Z",
     "start_time": "2021-04-08T08:55:48.567236Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "Fizzbuzz\n",
      "tensor和numpy的用时: 0.3779158592224121\n",
      "1\n",
      "2\n",
      "Fizz\n",
      "4\n",
      "Buzz\n",
      "Fizz\n",
      "7\n",
      "8\n",
      "Fizz\n",
      "Buzz\n",
      "11\n",
      "Fizz\n",
      "13\n",
      "14\n",
      "Fizzbuzz\n",
      "纯python变量的用时: 0.007978677749633789\n"
     ]
    }
   ],
   "source": [
    "# 官网示例\n",
    "def fizzbuzz(max_num):\n",
    "    counter = tf.constant(0)\n",
    "#     转换成tensor对象\n",
    "    max_num = tf.convert_to_tensor(max_num)\n",
    "#     转换成numpy对象，好奇怪，为啥不直接用numpy？或者直接python呢?\n",
    "    for num in range(1,max_num.numpy()+1):\n",
    "        num=tf.constant(num)\n",
    "        if int(num%3) == 0 and int(num % 5) ==0:\n",
    "            print('Fizzbuzz')\n",
    "        elif int(num % 3) == 0:\n",
    "            print('Fizz')\n",
    "        elif int(num % 5) == 0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num.numpy())\n",
    "        counter+=1\n",
    "def myfizzbuzz(maxnum):\n",
    "    counter=0\n",
    "    for num in range(1,maxnum+1):\n",
    "        num=tf.constant(num)\n",
    "        if int(num%3) == 0 and int(num % 5) ==0:\n",
    "            print('Fizzbuzz')\n",
    "        elif int(num % 3) == 0:\n",
    "            print('Fizz')\n",
    "        elif int(num % 5) == 0:\n",
    "            print('Buzz')\n",
    "        else:\n",
    "            print(num.numpy())\n",
    "        counter+=1\n",
    "\n",
    "# 看看使用tensor转换numpy和正常的python时间差多少\n",
    "from time import time\n",
    "start=time()\n",
    "fizzbuzz(15)\n",
    "end=time()\n",
    "print('tensor和numpy的用时:',end-start)\n",
    "# 0.38219308853149414\n",
    "\n",
    "start=time()\n",
    "myfizzbuzz(15)\n",
    "end=time()\n",
    "print('纯python变量的用时:',end-start)\n",
    "#  0.007972955703735352\n",
    "\n",
    "# 很明显啊，这部50多倍呢，我试试大的数字"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-sweet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:55:32.501184Z",
     "start_time": "2021-04-08T08:54:53.118Z"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 梯度训练\n",
    "自动微分对实现机器学习算法（例如用于训练神经网络的反向传播）十分有用。\n",
    "在 Eager Execution 期间，请使用** tf.GradientTape** 跟踪运算以便稍后计算梯度。\n",
    "<br>\n",
    "使用 tf.GradientTape 来训练和/或计算梯度。这对复杂的训练循环特别有用。\n",
    "由于在每次调用期间都可能进行不同运算，所有前向传递的运算都会记录到“条带”中。要计算梯度，请反向播放条带，然后丢弃。特定 tf.GradientTape 只能计算一个梯度；后续调用会引发运行时错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "connected-contrary",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T08:57:23.991513Z",
     "start_time": "2021-04-08T08:57:23.980545Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.]]\n"
     ]
    }
   ],
   "source": [
    "# 设置变量\n",
    "w=tf.Variable([\n",
    "    [1.0]\n",
    "])\n",
    "# 设置链式梯度\n",
    "with tf.GradientTape() as tape:\n",
    "    loss=w*w\n",
    "# 对w进行求导\n",
    "grad = tape.gradient(loss,w)\n",
    "print(grad.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "early-jerusalem",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T09:02:20.487929Z",
     "start_time": "2021-04-08T09:02:20.089452Z"
    }
   },
   "source": [
    "---\n",
    "\n",
    "## 训练模型\n",
    "对标准 MNIST 手写数字进行分类。示例演示了在 Eager Execution 环境中构建可训练计算图的优化器和层 API。O.O下不下来，很烦"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "medieval-purple",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T09:28:00.821703Z",
     "start_time": "2021-04-08T09:26:15.721335Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz: None -- [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTimeoutError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1349\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m                 h.request(req.get_method(), req.selector, req.data, headers,\n\u001b[0m\u001b[0;32m   1351\u001b[0m                           encode_chunked=req.has_header('Transfer-encoding'))\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mrequest\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1239\u001b[0m         \u001b[1;34m\"\"\"Send a complete request to the server.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1240\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1285\u001b[0m             \u001b[0mbody\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'body'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1286\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendheaders\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1287\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mendheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1234\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mCannotSendHeader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_send_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage_body\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencode_chunked\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencode_chunked\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[1;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1006\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    945\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauto_open\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 946\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    947\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1401\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1402\u001b[1;33m             \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\http\\client.py\u001b[0m in \u001b[0;36mconnect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    916\u001b[0m         \u001b[1;34m\"\"\"Connect to the host and port specified in __init__.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 917\u001b[1;33m         self.sock = self._create_connection(\n\u001b[0m\u001b[0;32m    918\u001b[0m             (self.host,self.port), self.timeout, self.source_address)\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    807\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 808\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\socket.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address)\u001b[0m\n\u001b[0;32m    795\u001b[0m                 \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m             \u001b[0msock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msa\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    797\u001b[0m             \u001b[1;31m# Break explicitly a reference cycle\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTimeoutError\u001b[0m: [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    274\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 275\u001b[1;33m         \u001b[0murlretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdl_progress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    276\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 247\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0mcontextlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    248\u001b[0m         \u001b[0mheaders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mopen\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    524\u001b[0m         \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maudit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'urllib.Request'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 525\u001b[1;33m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    526\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    541\u001b[0m         \u001b[0mprotocol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m         result = self._call_chain(self.handle_open, protocol, protocol +\n\u001b[0m\u001b[0;32m    543\u001b[0m                                   '_open', req)\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 502\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    503\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mhttps_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1392\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mhttps_open\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1393\u001b[1;33m             return self.do_open(http.client.HTTPSConnection, req,\n\u001b[0m\u001b[0;32m   1394\u001b[0m                 context=self._context, check_hostname=self._check_hostname)\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\urllib\\request.py\u001b[0m in \u001b[0;36mdo_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1352\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# timeout error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1353\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1354\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetresponse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-a53692fef6f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 导入数据集\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;33m(\u001b[0m\u001b[0mmnist_images\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmnist_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\mnist.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     56\u001b[0m   \"\"\"\n\u001b[0;32m     57\u001b[0m   \u001b[0morigin_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'https://storage.googleapis.com/tensorflow/tf-keras-datasets/'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m   path = get_file(\n\u001b[0m\u001b[0;32m     59\u001b[0m       \u001b[0mpath\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m       \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morigin_folder\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'mnist.npz'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\ProgramFiles\\anaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\data_utils.py\u001b[0m in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir)\u001b[0m\n\u001b[0;32m    277\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[0mURLError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 279\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merror_msg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morigin\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    280\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mException\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    281\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: URL fetch failure on https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz: None -- [WinError 10060] 由于连接方在一段时间后没有正确答复或连接的主机没有反应，连接尝试失败。"
     ]
    }
   ],
   "source": [
    "# 导入数据集\n",
    "(mnist_images,mnist_labels),_ = tf.keras.datasets.mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "entire-anaheim",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T09:26:10.167711Z",
     "start_time": "2021-04-08T09:26:10.142749Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-38-d763d56edfb7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m dataset = tf.data.Dataset.from_tensor_slices(\n\u001b[0;32m      2\u001b[0m     (\n\u001b[1;32m----> 3\u001b[1;33m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_images\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist_labels\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     )\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist_images' is not defined"
     ]
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        tf.cast(mnist_images[...,tf.newaxis]/255, tf.float32),\n",
    "        tf.cast(mnist_labels,tf.int64)\n",
    "    )\n",
    ")\n",
    "dataset=dataset.shuffle(1000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-reward",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T09:28:00.828667Z",
     "start_time": "2021-04-08T09:26:48.578Z"
    }
   },
   "outputs": [],
   "source": [
    "# Build the model\n",
    "mnist_model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu',\n",
    "                         input_shape=(None, None, 1)),\n",
    "  tf.keras.layers.Conv2D(16,[3,3], activation='relu'),\n",
    "  tf.keras.layers.GlobalAveragePooling2D(),\n",
    "  tf.keras.layers.Dense(10)\n",
    "])\n",
    "for images,labels in dataset.take(1):\n",
    "  print(\"Logits: \", mnist_model(images[0:1]).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "southwest-analysis",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T09:28:51.046309Z",
     "start_time": "2021-04-08T09:28:49.172471Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Loss [entropy]')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEGCAYAAABLgMOSAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Z1A+gAAAACXBIWXMAAAsTAAALEwEAmpwYAAAUXUlEQVR4nO3df5BlZX3n8fcnA5SrgsgyKDCjg2RWQ4wK6Yyo2WwUsGDCAsluEqyolG6WZTdUpIySUWortdla14RK4rIhIuuShYhhTQzFqGMhEPJjN8HQIIxBQCYULhMmMhrLIWKEwe/+cU8nl+Z295mn+/btpt+vqlN9z3Oec873qVvwmfPjnpOqQpKkA/U9ky5AkrQ6GSCSpCYGiCSpiQEiSWpigEiSmhw06QKW05FHHlmbNm2adBmStKrccccdX6uq9bPb11SAbNq0ienp6UmXIUmrSpKvjGr3FJYkqYkBIklqYoBIkpoYIJKkJgaIJKmJASJJamKASJKaGCCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqYkBIklqYoBIkpoYIJKkJgaIJKmJASJJamKASJKaGCCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqclEAyTJ6UnuT7IrybYRy5Pksm75ziQnzVq+LskXknx6+aqWJMEEAyTJOuBy4AzgBOAtSU6Y1e0MYHM3nQ98eNbydwH3jrlUSdIIkzwC2QLsqqoHq+oJ4Drg7Fl9zgauqYHbgMOTHA2QZAPwY8BHl7NoSdLAJAPkWODhofndXVvfPh8CLga+O99OkpyfZDrJ9N69exdVsCTpH00yQDKirfr0SXIm8GhV3bHQTqrqyqqaqqqp9evXt9QpSRphkgGyG9g4NL8BeKRnnzcAZyV5iMGprzcl+dj4SpUkzTbJALkd2JzkuCSHAOcC22f12Q68vbsb62Tgm1W1p6reV1UbqmpTt94fVtVbl7V6SVrjDprUjqtqf5ILgRuBdcBVVXVPkgu65VcAO4CtwC7gceAdk6pXkvR0qZp92eHZa2pqqqanpyddhiStKknuqKqp2e3+El2S1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNTFAJElNDBBJUhMDRJLUxACRJDUxQCRJTQwQSVITA0SS1MQAkSQ1MUAkSU0MEElSEwNEktTEAJEkNZlogCQ5Pcn9SXYl2TZieZJc1i3fmeSkrn1jkluT3JvkniTvWv7qJWltm1iAJFkHXA6cAZwAvCXJCbO6nQFs7qbzgQ937fuBX6iq7wNOBn5uxLqSpDGa5BHIFmBXVT1YVU8A1wFnz+pzNnBNDdwGHJ7k6KraU1V3AlTVY8C9wLHLWbwkrXWTDJBjgYeH5nfzzBBYsE+STcCJwOeXvkRJ0lwmGSAZ0VYH0ifJ84FPAhdV1b6RO0nOTzKdZHrv3r3NxUqSnm6SAbIb2Dg0vwF4pG+fJAczCI9rq+oP5tpJVV1ZVVNVNbV+/folKVySNNkAuR3YnOS4JIcA5wLbZ/XZDry9uxvrZOCbVbUnSYD/CdxbVb++vGVLkgAOmtSOq2p/kguBG4F1wFVVdU+SC7rlVwA7gK3ALuBx4B3d6m8A3gZ8McldXdv7q2rHMg5Bkta0VM2+7PDsNTU1VdPT05MuQ5JWlSR3VNXU7HZ/iS5JajLnKawk7+6x/req6iNLWI8kaZWY7wjkvcDzgUPnmX5h3AVKklam+S6i/05V/fJ8Kyd53hLXI0laJeY8Aqmqi+Efnlk1bx9J0trT5yL6riSX+rBCSdKwPgHyKuDLwEeT3NY9GuSwMdclSVrhFgyQqnqsqv5HVb0euBj4JWBPkquTfO/YK5QkrUgLBkiSdUnOSnI98N+AXwNeBnyKwS/FJUlrUJ9HmTwA3ApcWlV/NtT++0l+ZDxlSZJWuj4B8qqq+rtRC6rq55e4HknSKtHnIvpRST6V5GtJHk1yQ5KXjb0ySdKK1idAPg58AngxcAzwe8DvjrMoSdLK1ydAUlW/U1X7u+ljPPPNgZKkNabPNZBbk2wDrmMQHD8NfCbJEQBV9bdjrE+StEL1CZCf7v7+u1nt72QQKF4PkaQ1aMEAqarjlqMQSdLqsmCAJDkY+PfAzG8+/gj4SFU9Oca6JEkrXJ9TWB8GDgZ+q5t/W9f2s+MqSpK08vUJkB+qqlcPzf9hkrvHVZAkaXXocxvvU0mOn5npfkT41PhKkiStBn2OQN7D4FbeB4EALwXeMdaqJEkr3rwB0r2N8NXAZuDlDALkvqr6zjLUJklaweY9hVVVTwFnVdV3qmpnVd1teEiSoN8prD9L8pvA/wa+NdNYVXeOrSpJ0orXJ0Be3/395aG2At609OVIklaLPgHyb6rqweEGH+cuSepzG+/vj2j7vaUuRJK0usx5BJLkFcD3Ay9I8hNDiw4DnjPuwiRJK9t8p7BeDpwJHA78y6H2x4B/O8aaJEmrwJwBUlU3ADckeV1V/fky1iRJWgX6XAPZleT9Sa5MctXMtBQ7T3J6kvuT7OpeWjV7eZJc1i3fmeSkvutKksarz11YNwB/CtzMEj4Dq/uV++XAacBu4PYk26vqS0PdzmDwK/jNwGsZPAX4tT3XlSSNUZ8AeW5V/eIY9r0F2DVzi3CS64CzgeEQOBu4pqoKuC3J4UmOBjb1WFeSNEZ9TmF9OsnWMez7WODhofndXVufPn3WBSDJ+Ummk0zv3bt30UVLkgb6BMi7GITI3yfZl+SxJPuWYN8Z0VY9+/RZd9BYdWVVTVXV1Pr16w+wREnSXPq8E/3QMe17N7BxaH4D8EjPPof0WFeSNEYLHoF0d0K9Ncl/7OY3JtmyBPu+Hdic5LgkhwDnAttn9dkOvL2r4WTgm1W1p+e6kqQx6nMR/beA7zJ4eOJ/Bv6OwR1QP7SYHVfV/iQXAjcC64CrquqeJBd0y68AdgBbgV3A43Qvsppr3cXUI0k6MH0C5LVVdVKSLwBU1Te6f/UvWlXtYBASw21XDH0u4Of6ritJWj59LqI/2f3uogCSrGdwRCJJWsP6BMhlwPXAUUn+C/B/gA+MtSpJ0orX5y6sa5PcAZzC4PbZc6rq3rFXJkla0fpcA6Gq7gPuG3MtkqRVZM5TWEkWfOd5nz6SpGen+Y5Avi/JznmWB3jBEtcjSVol5guQV/RYf8mezitJWl3me6HUV5azEEnS6tLnNl5Jkp7BAJEkNenzMMXnJfme7vM/S3JWkoPHX5okaSXrcwTyJ8BzkhwL3MLggYb/a5xFSZJWvj4Bkqp6HPgJ4L9X1Y8DJ4y3LEnSStcrQJK8DvgZ4DNdW69fsEuSnr36BMhFwPuA67v3dbwMuHWsVUmSVrw+D1P8Y+CPAbqL6V+rqp8fd2GSpJWtz11YH09yWJLnAV8C7k/y3vGXJklayfqcwjqhqvYB5zB4A+BLgLeNsyhJ0srXJ0AO7n73cQ5wQ1U9Sfd2QknS2tUnQD4CPAQ8D/iTJC8F9o2zKEnSytfnIvplDF5rO+MrSd44vpIkSatBn4voL0jy60mmu+nXGByNSJLWsD6nsK4CHgN+qpv2Ab89zqIkSStfn1+UH19V/2po/j8luWtM9UiSVok+RyDfTvLDMzNJ3gB8e3wlSZJWgz5HIBcA1ySZef/5N4DzxleSJGk16HMX1t3Aq5Mc1s3vS3IRsHPMtUmSVrDebySsqn3dL9IB3j2meiRJq0TrK22zpFVIklad1gDxUSaStMbNGSBJHkuyb8T0GHDMYnaa5IgkNyV5oPv7wjn6nZ7k/iS7kmwbar80yX1Jdia5Psnhi6lHknTg5gyQqjq0qg4bMR1aVYt9I+E24Jaq2szgPevbZndIsg64HDiDwSt035Jk5lW6NwGvrKpXAV9m8MIrSdIyaj2FtVhnA1d3n69m8KTf2bYAu6rqwap6AriuW4+q+lxV7e/63QZsGG+5kqTZJhUgL6qqPQDd36NG9DkWeHhofnfXNts7gc8ueYWSpHkt9lTUnJLcDLx4xKJL+m5iRNvTLt4nuQTYD1w7Tx3nA+cDvOQlL+m5a0nSQsYWIFV16lzLknw1ydFVtSfJ0cCjI7rtBjYOzW8AHhnaxnnAmcApVTXnXWFVdSVwJcDU1JR3j0nSEpnUKazt/OPjUM4DbhjR53Zgc5LjkhwCnNutR5LTgV8Ezqqqx5ehXknSLJMKkA8CpyV5ADitmyfJMUl2AHQXyS8EbgTuBT5RVfd06/8mcChwU5K7klyx3AOQpLVubKew5lNVXwdOGdH+CLB1aH4HsGNEv+8da4GSpAVN6ghEkrTKGSCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqYkBIklqYoBIkpoYIJKkJgaIJKmJASJJamKASJKaGCCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqYkBIklqYoBIkpoYIJKkJgaIJKmJASJJamKASJKaGCCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqclEAiTJEUluSvJA9/eFc/Q7Pcn9SXYl2TZi+XuSVJIjx1+1JGnYpI5AtgG3VNVm4JZu/mmSrAMuB84ATgDekuSEoeUbgdOA/7csFUuSnmZSAXI2cHX3+WrgnBF9tgC7qurBqnoCuK5bb8ZvABcDNcY6JUlzmFSAvKiq9gB0f48a0edY4OGh+d1dG0nOAv66qu5eaEdJzk8ynWR67969i69ckgTAQePacJKbgRePWHRJ302MaKskz+228eY+G6mqK4ErAaampjxakaQlMrYAqapT51qW5KtJjq6qPUmOBh4d0W03sHFofgPwCHA8cBxwd5KZ9juTbKmqv1myAUiS5jWpU1jbgfO6z+cBN4zoczuwOclxSQ4BzgW2V9UXq+qoqtpUVZsYBM1JhockLa9JBcgHgdOSPMDgTqoPAiQ5JskOgKraD1wI3AjcC3yiqu6ZUL2SpFnGdgprPlX1deCUEe2PAFuH5ncAOxbY1qalrk+StDB/iS5JamKASJKaGCCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqYkBIklqYoBIkpoYIJKkJgaIJKmJASJJamKASJKaGCCSpCYGiCSpiQEiSWpigEiSmhggkqQmBogkqYkBIklqYoBIkpoYIJKkJgaIJKlJqmrSNSybJHuBr0y6jgZHAl+bdBHLaK2NFxzzWrFax/zSqlo/u3FNBchqlWS6qqYmXcdyWWvjBce8VjzbxuwpLElSEwNEktTEAFkdrpx0ActsrY0XHPNa8awas9dAJElNPAKRJDUxQCRJTQyQFSDJEUluSvJA9/eFc/Q7Pcn9SXYl2TZi+XuSVJIjx1/14ix2zEkuTXJfkp1Jrk9y+LIVf4B6fG9Jclm3fGeSk/quu1K1jjnJxiS3Jrk3yT1J3rX81bdZzPfcLV+X5AtJPr18VS9SVTlNeAJ+FdjWfd4G/MqIPuuAvwJeBhwC3A2cMLR8I3Ajgx9KHjnpMY17zMCbgYO6z78yav2VMC30vXV9tgKfBQKcDHy+77orcVrkmI8GTuo+Hwp8+dk+5qHl7wY+Dnx60uPpO3kEsjKcDVzdfb4aOGdEny3Arqp6sKqeAK7r1pvxG8DFwGq5K2JRY66qz1XV/q7fbcCG8ZbbbKHvjW7+mhq4DTg8ydE9112JmsdcVXuq6k6AqnoMuBc4djmLb7SY75kkG4AfAz66nEUvlgGyMryoqvYAdH+PGtHnWODhofndXRtJzgL+uqruHnehS2hRY57lnQz+ZbcS9RnDXH36jn+lWcyY/0GSTcCJwOeXvsQlt9gxf4jBPwC/O6b6xuKgSRewViS5GXjxiEWX9N3EiLZK8txuG29urW1cxjXmWfu4BNgPXHtg1S2bBccwT58+665EixnzYGHyfOCTwEVVtW8JaxuX5jEnORN4tKruSPKjS13YOBkgy6SqTp1rWZKvzhy+d4e0j47otpvBdY4ZG4BHgOOB44C7k8y035lkS1X9zZINoMEYxzyzjfOAM4FTqjuJvALNO4YF+hzSY92VaDFjJsnBDMLj2qr6gzHWuZQWM+Z/DZyVZCvwHOCwJB+rqreOsd6lMemLME4FcClPv6D8qyP6HAQ8yCAsZi7Sff+Ifg+xOi6iL2rMwOnAl4D1kx7LAuNc8HtjcO57+OLqXxzId77SpkWOOcA1wIcmPY7lGvOsPj/KKrqIPvECnArgnwK3AA90f4/o2o8Bdgz128rgrpS/Ai6ZY1urJUAWNWZgF4PzyXd10xWTHtM8Y33GGIALgAu6zwEu75Z/EZg6kO98JU6tYwZ+mMGpn51D3+3WSY9n3N/z0DZWVYD4KBNJUhPvwpIkNTFAJElNDBBJUhMDRJLUxACRJDUxQKRGSZ5KcleSu5PcmeT1C/Q/PMl/6LHdP0oydQB1/G6STUkuSnJu3/WkxTJApHbfrqrXVNWrgfcB/3WB/ocDCwZIg+Oq6iHgXwB/OobtSyMZINLSOAz4Bgye45Tklu6o5ItJZp7K+kHg+O6o5dKu78Vdn7uTfHBoez+Z5C+SfDnJPx+1wyTXJvkS8PIkdzF4HtpnkvzsuAYpDfNZWFK7f9L9j/s5DN5j8aau/e+BH6+qfd3LvW5Lsp3BI1teWVWvAUhyBoPH2L+2qh5PcsTQtg+qqi3d85F+CXjGc8Wq6meS/BSD5yt9Eri0qn5yDOOURjJApHbfHgqD1wHXJHklg0dWfCDJjzB4PPexwItGrH8q8NtV9ThAVf3t0LKZhwjeAWyap4YTgZuBH2Dw2A9p2Rgg0hKoqj/vjjbWM3gm0nrgB6vqySQPMThKmS3M/Xj273R/n2LEf6fdkckHGDy878xuf99KcmpVvXExY5H68hqItASSvILBa02/DryAwfsdnkzyRuClXbfHGLymdcbngHd273Rh1imseVXVDuAHgb+sqh8A7gFONDy0nDwCkdrNXAOBwdHEeVX1VJJrgU8lmWZwWuk+gKr6epL/m+Qvgc9W1XuTvAaYTvIEsAN4/wHs/0QG74E5BDi4VseLl/Qs4tN4JUlNPIUlSWpigEiSmhggkqQmBogkqYkBIklqYoBIkpoYIJKkJv8f4/9+dlU5/ssAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "\n",
    "loss_history = []\n",
    "def train_step(images, labels):\n",
    "  with tf.GradientTape() as tape:\n",
    "    logits = mnist_model(images, training=True)\n",
    "\n",
    "    # Add asserts to check the shape of the output.\n",
    "    tf.debugging.assert_equal(logits.shape, (32, 10))\n",
    "\n",
    "    loss_value = loss_object(labels, logits)\n",
    "\n",
    "  loss_history.append(loss_value.numpy().mean())\n",
    "  grads = tape.gradient(loss_value, mnist_model.trainable_variables)\n",
    "  optimizer.apply_gradients(zip(grads, mnist_model.trainable_variables))\n",
    "def train(epochs):\n",
    "  for epoch in range(epochs):\n",
    "    for (batch, (images, labels)) in enumerate(dataset):\n",
    "      train_step(images, labels)\n",
    "    print ('Epoch {} finished'.format(epoch))\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(loss_history)\n",
    "plt.xlabel('Batch #')\n",
    "plt.ylabel('Loss [entropy]')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-drain",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 变量和优化器\n",
    "\n",
    "tf.Variable 对象会**存储在训练期间访问的可变**、类似于 tf.Tensor 的值，以更简单地实现自动微分。\n",
    "以上面自动微分示例可以用以下步骤来代替:\n",
    "1. 基于keras.model的基础上定义自己的模型\n",
    "2. 定义自己的损失函数\n",
    "3. 定义自己的梯度\n",
    "4. 迭代进行梯度的更新"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "differential-therapist",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T09:47:36.638183Z",
     "start_time": "2021-04-08T09:47:36.627215Z"
    }
   },
   "outputs": [],
   "source": [
    "# 定义线性模型\n",
    "class Liner(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Liner,self).__init__()\n",
    "        self.W=tf.Variable(5.,name='weight')\n",
    "        self.B=tf.Variable(10.,name='bias')\n",
    "    def call(self,inputs):\n",
    "        return inputs*self.W+self.B\n",
    "# 样本数量为2000\n",
    "num_examples=2000\n",
    "training_inputs=tf.random.normal([num_examples])\n",
    "noise = tf.random.normal([num_examples])\n",
    "training_outputs = training_inputs * 3 + 2 + noise\n",
    "# 定义自己的损失函数\n",
    "def loss(model, inputs, targets):\n",
    "  error = model(inputs) - targets\n",
    "  return tf.reduce_mean(tf.square(error))\n",
    "# 求解返回自己定义的梯度\n",
    "def grad(model, inputs, targets):\n",
    "  with tf.GradientTape() as tape:\n",
    "    loss_value = loss(model, inputs, targets)\n",
    "  return tape.gradient(loss_value, [model.W, model.B])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "conventional-police",
   "metadata": {},
   "source": [
    "下一步：\n",
    "\n",
    "   1. 创建模型。\n",
    "   2. 损失函数对模型参数的导数。\n",
    "   3. 基于导数的变量更新策略。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "respiratory-samba",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T09:52:02.204931Z",
     "start_time": "2021-04-08T09:52:01.231507Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss: 68.481\n",
      "Loss at step 000: 65.799\n",
      "Loss at step 020: 29.786\n",
      "Loss at step 040: 13.780\n",
      "Loss at step 060: 6.666\n",
      "Loss at step 080: 3.504\n",
      "Loss at step 100: 2.098\n",
      "Loss at step 120: 1.472\n",
      "Loss at step 140: 1.194\n",
      "Loss at step 160: 1.071\n",
      "Loss at step 180: 1.016\n",
      "Loss at step 200: 0.991\n",
      "Loss at step 220: 0.981\n",
      "Loss at step 240: 0.976\n",
      "Loss at step 260: 0.974\n",
      "Loss at step 280: 0.973\n"
     ]
    }
   ],
   "source": [
    "# 创建线性模型\n",
    "model=Liner()\n",
    "# 创建优化函数\n",
    "optimizer=tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "print(\"Initial loss: {:.3f}\".format(loss(model, training_inputs, training_outputs)))\n",
    "steps=300\n",
    "# 迭代进行梯度下降来更新数值\n",
    "for i in range(steps):\n",
    "    grads=grad(model,training_inputs,training_outputs)\n",
    "    optimizer.apply_gradients(zip(grads,[model.W,model.B]))\n",
    "    if i % 20 == 0:\n",
    "        print(\"Loss at step {:03d}: {:.3f}\".format(i, loss(model, training_inputs, training_outputs)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-vector",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# 张量\n",
    "张量是具有统一类型（称为 dtype）的多维数组。所有张量都是不可变的：永远无法更新张量的内容，只能创建新的张量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mediterranean-mount",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T12:31:52.702808Z",
     "start_time": "2021-04-08T12:31:51.188768Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 4.], shape=(3,), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]\n",
      " [5 6]], shape=(3, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "rank_1_tensor=tf.constant([2.0,3.0,4.0])\n",
    "print(rank_1_tensor)\n",
    "\n",
    "rank_2_tensor=tf.constant([\n",
    "    [1,2],\n",
    "    [3,4],\n",
    "    [5,6]\n",
    "])\n",
    "print(rank_2_tensor)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "geological-convert",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "通过使用 np.array 或 tensor.numpy 方法，您可以将张量转换为 NumPy 数组"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dominant-minister",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T12:33:06.756945Z",
     "start_time": "2021-04-08T12:33:06.749964Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 3. 4.]\n",
      "[2. 3. 4.]\n"
     ]
    }
   ],
   "source": [
    "# 两种方法，一个是通过np来转换，一个是通过tensor进行转换\n",
    "_rank_1_tensor=np.array(rank_1_tensor)\n",
    "print(_rank_1_tensor)\n",
    "_rank_1_tensor_=rank_1_tensor.numpy()\n",
    "print(_rank_1_tensor_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "solved-lesson",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## 通过张量进行基本的算数运算\n",
    "\n",
    "简写方法：\n",
    "```code\n",
    "print(a + b, \"\\n\") # 广播加法\n",
    "print(a * b, \"\\n\") # 广播乘法\n",
    "print(a @ b, \"\\n\") # 矩阵乘法\n",
    "\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "signal-symphony",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T12:35:19.601709Z",
     "start_time": "2021-04-08T12:35:18.587389Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2 3]\n",
      " [4 5]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[1 2]\n",
      " [3 4]], shape=(2, 2), dtype=int32) \n",
      "\n",
      "tf.Tensor(\n",
      "[[3 3]\n",
      " [7 7]], shape=(2, 2), dtype=int32) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = tf.constant([[1, 2],\n",
    "                 [3, 4]])\n",
    "b = tf.constant([[1, 1],\n",
    "                 [1, 1]])\n",
    "# 广播加法\n",
    "print(tf.add(a, b), \"\\n\")\n",
    "# 广播乘法\n",
    "print(tf.multiply(a, b), \"\\n\")\n",
    "# 矩阵的乘法\n",
    "print(tf.matmul(a, b), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "right-librarian",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T12:46:22.184373Z",
     "start_time": "2021-04-08T12:46:21.737425Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(10.0, shape=(), dtype=float32)\n",
      "tf.Tensor(5.0, shape=(), dtype=float32)\n",
      "tf.Tensor([1 0], shape=(2,), dtype=int64)\n",
      "tf.Tensor(\n",
      "[[2.6894143e-01 7.3105854e-01]\n",
      " [9.9987662e-01 1.2339458e-04]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "c = tf.constant([[4.0, 5.0], [10.0, 1.0]])\n",
    "# 输出最大值\n",
    "print(tf.reduce_max(c))\n",
    "# 输出平均值\n",
    "print(tf.reduce_mean(c))\n",
    "# 输出下边最大的\n",
    "print(tf.argmax(c))\n",
    "# 以softmax来进行输出\n",
    "print(tf.nn.softmax(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "incorporate-carpet",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T12:48:30.637358Z",
     "start_time": "2021-04-08T12:48:30.245535Z"
    }
   },
   "outputs": [],
   "source": [
    "rank_4_tensor = tf.zeros([3, 2, 4, 5])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "improved-breakdown",
   "metadata": {},
   "source": [
    "<div>\n",
    "    <div style=\"float:left\">\n",
    "        <img  src=\"https://tensorflow.google.cn/guide/images/tensor/shape2.png\"/>\n",
    "    </div>\n",
    "    <div style=\"float:left\">\n",
    "        <img  style=\"zoom:50%;\" src=\"https://tensorflow.google.cn/guide/images/tensor/4-axis_block.png\"/>\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-ensemble",
   "metadata": {},
   "source": [
    "## 操作形状\n",
    "<br>\n",
    "通过重构可以改变张量的形状。**重构的速度很快，资源消耗很低**，因为不需要复制底层数据。\n",
    "<br>\n",
    "数据在内存中的布局保持不变，同时使用请求的形状创建一个指向同一数据的新张量。TensorFlow 采用 C 样式的“行优先”内存访问顺序，即最右侧的索引值递增对应于内存中的单步位移。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "material-external",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:10:43.738237Z",
     "start_time": "2021-04-08T13:10:43.319514Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 1)\n",
      "(1, 3)\n",
      "tf.Tensor(3, shape=(), dtype=int32)\n",
      "tf.Tensor(1, shape=(), dtype=int32)\n",
      "tf.Tensor([1 2 3], shape=(3,), dtype=int32)\n",
      "tf.Tensor([[1 2 3]], shape=(1, 3), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# 变换矩阵形式\n",
    "var_x = tf.Variable(tf.constant([[1], [2], [3]]))\n",
    "print(var_x.shape)\n",
    "r_var_x=tf.reshape(var_x,[1,3])\n",
    "print(r_var_x.shape)\n",
    "print(var_x[2,0])\n",
    "print(r_var_x[0,0])\n",
    "# 展平张量\n",
    "print(tf.reshape(r_var_x,[-1]))\n",
    "\n",
    "# 矩阵转置\n",
    "print(tf.transpose(var_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "monthly-franklin",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:13:18.563306Z",
     "start_time": "2021-04-08T13:13:18.559317Z"
    }
   },
   "source": [
    "## 不规则张量\n",
    "\n",
    "如果张量的某个轴上的元素个数可变，则称为“不规则”张量。对于不规则数据，请使用 tf.ragged.RaggedTensor。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "whole-india",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:15:32.311339Z",
     "start_time": "2021-04-08T13:15:32.303369Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.RaggedTensor [[0, 1, 2, 3], [4, 5], [6, 7, 8], [9]]>\n",
      "(4, None)\n"
     ]
    }
   ],
   "source": [
    "ragged_list = [\n",
    "    [0, 1, 2, 3],\n",
    "    [4, 5],\n",
    "    [6, 7, 8],\n",
    "    [9]]\n",
    "ragged_tensor = tf.ragged.constant(ragged_list)\n",
    "print(ragged_tensor)\n",
    "print(ragged_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bearing-demand",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:15:44.010663Z",
     "start_time": "2021-04-08T13:15:43.973736Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'\\xf0\\x9f\\xa5\\xb3\\xf0\\x9f\\x91\\x8d', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "a=tf.constant(\"🥳👍\")\n",
    "print(a)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
