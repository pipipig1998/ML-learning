{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "diagnostic-chrome",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:41:03.893692Z",
     "start_time": "2021-04-08T13:41:03.888695Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "together-transaction",
   "metadata": {},
   "source": [
    "# 自动微分和梯度带\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-ensemble",
   "metadata": {},
   "source": [
    "## 梯度带\n",
    "\n",
    "TensorFlow 为自动微分提供了 tf.GradientTape API ，根据某个函数的输入变量来计算它的导数。Tensorflow 会把 <br><br>\n",
    "\n",
    "'tf.GradientTape' 上下文中执行的所有操作都记录在一个磁带上 (\"tape\")。<br><br> \n",
    "\n",
    "然后基于这个磁带和每次操作产生的导数，用反向微分法（\"reverse mode differentiation\"）来计算这些被“记录在案”的函数的导数。\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "prompt-identification",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:46:33.504835Z",
     "start_time": "2021-04-08T13:46:33.488865Z"
    },
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(4.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[8. 8.]\n",
      " [8. 8.]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.ones((2,2))\n",
    "with tf.GradientTape() as t:\n",
    "    t.watch(x)\n",
    "    y=tf.reduce_sum(x)\n",
    "    z=tf.multiply(y,y)\n",
    "dz_dx = t.gradient(z, x)\n",
    "for i in [0, 1]:\n",
    "  for j in [0, 1]:\n",
    "    assert dz_dx[i][j].numpy() == 8.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competitive-exemption",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:49:32.627395Z",
     "start_time": "2021-04-08T13:49:32.225401Z"
    }
   },
   "source": [
    "默认情况下，调用 GradientTape.gradient() 方法时， GradientTape 占用的资源会立即得到释放。<br><br>\n",
    "通过创建一个持久的梯度带，可以计算同个函数的多个导数。这样在磁带对象被垃圾回收时，就可以多次调用 'gradient()' 方法。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "hollywood-yorkshire",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:52:21.135831Z",
     "start_time": "2021-04-08T13:52:21.125859Z"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.constant(3.0)\n",
    "with tf.GradientTape(persistent=True) as t:\n",
    "  t.watch(x)\n",
    "  y = x * x\n",
    "  z = y * y\n",
    "dz_dx = t.gradient(z, x)  # 108.0 (4*x^3 at x = 3)\n",
    "dy_dx = t.gradient(y, x)  # 6.0\n",
    "assert dz_dx==108\n",
    "assert dy_dx==6.0\n",
    "del t  # Drop the reference to the tape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "grave-switzerland",
   "metadata": {},
   "source": [
    "由于磁带会记录所有执行的操作，Python 控制流（如使用 if 和 while 的代码段）自然得到了处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "chicken-speaker",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:55:34.658206Z",
     "start_time": "2021-04-08T13:55:34.645241Z"
    }
   },
   "outputs": [],
   "source": [
    "def f(x, y):\n",
    "  output = 1.0\n",
    "  for i in range(y):\n",
    "    if i > 1 and i < 5:\n",
    "      output = tf.multiply(output, x)\n",
    "  return output\n",
    "def grad(x,y):\n",
    "    with tf.GradientTape() as t:\n",
    "        t.watch(x)\n",
    "        out=f(x,y)\n",
    "    return t.gradient(out,x)\n",
    "x=tf.convert_to_tensor(2.0)\n",
    "assert grad(x, 6).numpy() == 12.0\n",
    "assert grad(x, 5).numpy() == 12.0\n",
    "assert grad(x, 4).numpy() == 4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "educational-stake",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:56:20.930727Z",
     "start_time": "2021-04-08T13:56:20.924763Z"
    }
   },
   "source": [
    "## 高阶导数\n",
    "在 'GradientTape' 上下文管理器中记录的操作会用于自动微分。<br><br>\n",
    "\n",
    "如果导数是在上下文中计算的，导数的函数也会被记录下来。因此，同个 API 可以用于高阶导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aerial-arthur",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-08T13:58:41.003580Z",
     "start_time": "2021-04-08T13:58:40.993607Z"
    }
   },
   "outputs": [],
   "source": [
    "x=tf.Variable(1.0)\n",
    "with tf.GradientTape() as t:\n",
    "    with tf.GradientTape() as t2:\n",
    "        y=x**3\n",
    "    dy_dx=t2.gradient(y,x)\n",
    "d2y_d2x=t.gradient(y,x)\n",
    "assert dy_dx==d2y_d2x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "complimentary-atlas",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
